# Scrape Ops â€” Scrapy Projects Collection

This repository contains all my Scrapy projects built while following the **Scrapy Beginners Series** from [ScrapeOps](https://scrapeops.io/python-scrapy-playbook/scrapy-beginners-guide/).

Each project has its own **virtual environment** and **Scrapy setup** to keep dependencies isolated.

---

## ðŸ“‚ Project Structure

scrape_ops/
â”‚
â”œâ”€â”€ chocolatescraper/ # Project 1: Chocolate Website Scraper
â”‚ â”œâ”€â”€ venv/ # Virtual environment (not tracked by Git)
â”‚ â”œâ”€â”€ chocolatescraper/ # Scrapy project files
â”‚ â”œâ”€â”€ scrapy.cfg
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ coffeescraper/ # Project 2: Coffee Product Scraper (future)
â”‚ â”œâ”€â”€ venv/
â”‚ â”œâ”€â”€ coffeescraper/
â”‚ â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md
---

## ðŸš€ Getting Started

1. **Clone this repository**
   ```bash
   git clone https://github.com/<your-username>/scrape_ops.git
  cd chocolatescrapersource venv/bin/activate scrapy crawl <spider_name> | Project Name     | Description                                                         | Status      |
| ---------------- | ------------------------------------------------------------------- | ----------- |
| chocolatescraper | Scrapes chocolate data from target website (Beginner Series Part 1) | âœ… Completed |
| coffeescraper    | Scrapes coffee product data (Beginner Series Part 2)                | â³ Pending   |
# Inside the project folder
python3 -m venv venv
source venv/bin/activate
pip install scrapy
pip freeze > requirements.txt
ðŸ”„ Git Workflow
All commits are done from the parent folder scrape_ops/ unless specified otherwise.# Check status
git status

# Add changes
git add .

# Commit changes
git commit -m "Meaningful commit message"

# Push to GitHub
git push origin main
ðŸ“š Resources
Scrapy Documentation

ScrapeOps Scrapy Beginners Guide

yaml
Copy
Edit


